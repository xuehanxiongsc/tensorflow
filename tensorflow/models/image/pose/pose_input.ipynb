{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SCALE_MIN = 0.7\n",
    "SCALE_MAX = 1.3\n",
    "SCALE_ABS = 1.171\n",
    "SIGMA = 7.0\n",
    "\n",
    "# tf.app.flags.DEFINE_float('scale_min', 0.7,\n",
    "#                           \"\"\"Maximum downscale perturbation.\"\"\")\n",
    "# tf.app.flags.DEFINE_float('scale_max', 1.3,\n",
    "#                           \"\"\"Maximum upscale perturbation.\"\"\")\n",
    "# tf.app.flags.DEFINE_float('scale_abs', 1.171,\n",
    "#                           \"\"\"Absolute scale.\"\"\")\n",
    "# tf.app.flags.DEFINE_float('sigma', 16.0,\n",
    "#                           \"\"\"Sigma for joint heatmap.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# joint configuration\n",
    "RIGHT_ANKLE=0\n",
    "RIGHT_KNEE=1\n",
    "RIGHT_HIP=2\n",
    "LEFT_HIP=3\n",
    "LEFT_KNEE=4\n",
    "LEFT_ANKLE=5\n",
    "RIGHT_WRIST=6\n",
    "RIGHT_ELBOW=7\n",
    "RIGHT_SHOULDER=8\n",
    "LEFT_SHOULDER=9\n",
    "LEFT_ELBOW=10\n",
    "LEFT_WRIST=11\n",
    "NECK=12\n",
    "HEAD_TOP=13\n",
    "\n",
    "IMAGE_SIZE = 368\n",
    "IMAGE_SIZE_HALF = IMAGE_SIZE/2\n",
    "NUM_MPI_JOINTS = 16\n",
    "NUM_COMMON_JOINTS = 14\n",
    "NUM_HEATMAPS = NUM_COMMON_JOINTS+1\n",
    "NORMALIZER = 1.0/(2*SIGMA*SIGMA)\n",
    "TRANSLATION_PERTURB = 10\n",
    "IMAGE_SIZE_WITH_PADDING = IMAGE_SIZE + 2*TRANSLATION_PERTURB\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        # Defaults are not specified since both keys are required.\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([],tf.string),\n",
    "            'height': tf.FixedLenFeature([],tf.int64),\n",
    "            'width': tf.FixedLenFeature([],tf.int64),\n",
    "            'num_people': tf.FixedLenFeature([],tf.int64),\n",
    "            'scales': tf.VarLenFeature(tf.float32),\n",
    "            'joints': tf.VarLenFeature(tf.float32),\n",
    "            'centers': tf.VarLenFeature(tf.float32)\n",
    "        })\n",
    "    height = tf.cast(features['height'],tf.int32)\n",
    "    width = tf.cast(features['width'],tf.int32)\n",
    "    nop = tf.cast(features['num_people'],tf.int32)\n",
    "    scales = tf.sparse_tensor_to_dense(features['scales'])\n",
    "    joints = tf.sparse_tensor_to_dense(features['joints'])\n",
    "    joints = tf.reshape(joints, [NUM_MPI_JOINTS*nop,3])\n",
    "    centers = tf.sparse_tensor_to_dense(features['centers'])\n",
    "    centers = tf.reshape(centers,[nop,2])\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, tf.pack([height, width, 3]))\n",
    "\n",
    "    return image,height,width,nop,scales,centers,joints\n",
    "\n",
    "def _reorder_joints(joints):\n",
    "    indices = [0,1,2,3,4,5,10,11,12,13,14,15,8,9]\n",
    "    reordered_joints = tf.gather(joints,indices)\n",
    "    return reordered_joints\n",
    "\n",
    "def _random_resize(image,joints,center,scale):\n",
    "    \n",
    "    scale_abs = SCALE_ABS/scale\n",
    "    scale_mul = tf.random_uniform([1], minval=SCALE_MIN, \n",
    "                                  maxval=SCALE_MAX)\n",
    "    scale_rnd = scale_mul[0] * scale_abs\n",
    "    resized_joints = tf.scalar_mul(scale_rnd,joints)\n",
    "    resized_center = tf.scalar_mul(scale_rnd,center)\n",
    "    new_width  = tf.cast(tf.cast(tf.shape(image)[1],tf.float32)*scale_rnd,tf.int32)\n",
    "    new_height = tf.cast(tf.cast(tf.shape(image)[0],tf.float32)*scale_rnd,tf.int32)\n",
    "    resized_image  = tf.image.resize_images(image, \n",
    "                                            [new_height, new_width])\n",
    "    return resized_image,resized_joints,resized_center\n",
    "\n",
    "def _add_invisible_joint_heatmap(heatmap, joint):\n",
    "    return heatmap\n",
    "\n",
    "def _add_visible_joint_heatmap(heatmap, joint):\n",
    "    height = tf.shape(heatmap)[0]\n",
    "    width  = tf.shape(heatmap)[1]\n",
    "    ones = tf.ones_like(heatmap)\n",
    "    joint_x = joint[0] * ones\n",
    "    joint_y = joint[1] * ones\n",
    "    \n",
    "    y_range = tf.range(height)\n",
    "    x_range = tf.range(width)\n",
    "    X,Y = tf.meshgrid(x_range,y_range)\n",
    "    X = tf.to_float(X)\n",
    "    Y = tf.to_float(Y)\n",
    "    D = (tf.square(joint_x-X)+tf.square(joint_y-Y))*NORMALIZER\n",
    "    threshold_mask = tf.cast(D < 4.6052,tf.float32)\n",
    "    D = tf.mul(tf.exp(-D),threshold_mask)\n",
    "    D = D + heatmap\n",
    "    D = tf.clip_by_value(D,0.0,1.0)\n",
    "    return D\n",
    "\n",
    "def _add_joint_heatmap(heatmap, joint, vis):\n",
    "    # the joints is outside image if vis < 0\n",
    "    return tf.cond(vis >= 0.0,\n",
    "                   lambda: _add_visible_joint_heatmap(heatmap, joint),\n",
    "                   lambda: _add_invisible_joint_heatmap(heatmap, joint))\n",
    "    \n",
    "def _background_heatmap(joint_heatmaps):\n",
    "    heatmap_sum = tf.reduce_sum(joint_heatmaps,reduction_indices=2)\n",
    "    ones = tf.ones_like(heatmap_sum)\n",
    "    output = ones-heatmap_sum\n",
    "    output = tf.clip_by_value(output,0.0,1.0)\n",
    "    return output\n",
    "\n",
    "def _add_background_heatmap(heatmap):\n",
    "    background_heatmap = _background_heatmap(heatmap)\n",
    "    background_heatmap = tf.expand_dims(background_heatmap,2)\n",
    "    heatmap = tf.concat(2,[heatmap,background_heatmap])\n",
    "    return heatmap\n",
    "\n",
    "def _generate_self_heatmaps(height,width,joints,joints_vis):\n",
    "    reordered_joints = _reorder_joints(joints[0,:,:])\n",
    "    reordered_joints_vis = _reorder_joints(joints_vis[0,:])\n",
    "    heatmap_overall = tf.zeros([height,width,1])\n",
    "    for i in xrange(NUM_COMMON_JOINTS):\n",
    "        heatmapi = tf.zeros(shape=[height,width])\n",
    "        heatmapi = _add_joint_heatmap(heatmapi, \n",
    "                                      reordered_joints[i,:], \n",
    "                                      reordered_joints_vis[i])\n",
    "        heatmapi = tf.expand_dims(heatmapi,2)\n",
    "        heatmap_overall = tf.concat(2,[heatmap_overall,heatmapi])\n",
    "    heatmap_overall = tf.slice(heatmap_overall,[0,0,1],[height,width,NUM_COMMON_JOINTS])\n",
    "    return heatmap_overall\n",
    "\n",
    "def _update_heatmaps(heatmaps,index,height,width,joints,joints_vis):\n",
    "    reordered_joints = _reorder_joints(joints[index,:,:])\n",
    "    reordered_joints_vis = _reorder_joints(joints_vis[index,:])\n",
    "    heatmap_overall = tf.zeros([height,width,1])\n",
    "    for i in xrange(NUM_COMMON_JOINTS):\n",
    "        heatmapi = _add_joint_heatmap(heatmaps[:,:,i], \n",
    "                                      reordered_joints[i,:], \n",
    "                                      reordered_joints_vis[i])\n",
    "        heatmapi = tf.expand_dims(heatmapi,2)\n",
    "        heatmap_overall = tf.concat(2,[heatmap_overall,heatmapi])\n",
    "    heatmap_overall = tf.slice(heatmap_overall,[0,0,1],[height,width,NUM_COMMON_JOINTS])    \n",
    "    return heatmap_overall\n",
    "\n",
    "def generate_heatmaps(height,width,joints,joints_vis,nop):\n",
    "    self_heatmaps = _generate_self_heatmaps(height,width,joints,joints_vis)\n",
    "    all_heatmaps = tf.identity(self_heatmaps)\n",
    "    \n",
    "    i0 = tf.constant(1)\n",
    "    cond = lambda i, heatmap: i < nop\n",
    "    body = lambda i, heatmap: [i+1, _update_heatmaps(heatmap,i,height,width,joints,joints_vis)]\n",
    "    all_heatmaps = tf.while_loop(cond, body, \n",
    "                                 loop_vars=[i0, all_heatmaps])  \n",
    "    all_heatmaps = all_heatmaps[1]\n",
    "    self_heatmaps = _add_background_heatmap(self_heatmaps)\n",
    "    all_heatmaps = _add_background_heatmap(all_heatmaps)\n",
    "    all_heatmaps = tf.concat(2,[self_heatmaps,all_heatmaps])\n",
    "    return all_heatmaps\n",
    "\n",
    "def _crop_pad(image, center, joints, size):\n",
    "    height = tf.shape(image)[0]\n",
    "    width  = tf.shape(image)[1]\n",
    "    x_start = tf.cast(center[0]-(size-1)*0.5,tf.int32)\n",
    "    x_end = x_start + size\n",
    "    pad_width = tf.cast(x_start < 0,tf.int32)*-x_start\n",
    "    pad_image_width = tf.cond(x_end > width, \n",
    "                              lambda: x_end+pad_width,\n",
    "                              lambda: width+pad_width)\n",
    "    y_start = tf.cast(center[1]-(size-1)*0.5,tf.int32)\n",
    "    y_end = y_start + size\n",
    "    pad_height = tf.cast(y_start < 0,tf.int32)*-y_start\n",
    "    pad_image_height = tf.cond(y_end > height, \n",
    "                               lambda: y_end+pad_height,\n",
    "                               lambda: height+pad_height)\n",
    "    pad_image = tf.image.pad_to_bounding_box(image,pad_height,pad_width,\n",
    "                                             pad_image_height,\n",
    "                                             pad_image_width)\n",
    "    \n",
    "    crop_x = tf.cast(x_start >= 0,tf.int32)*x_start\n",
    "    crop_y = tf.cast(y_start >= 0,tf.int32)*y_start\n",
    "    crop_image = tf.image.crop_to_bounding_box(pad_image,crop_y,crop_x,\n",
    "                                               size,size)\n",
    "    \n",
    "    crop_joints = tf.add(joints,tf.cast([pad_width-crop_x,pad_height-crop_y],tf.float32))\n",
    "    return crop_image,crop_joints\n",
    "    \n",
    "def distorted_inputs(filenames,batch_size,total_inputs):\n",
    "    # read a batch of images and labels\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    image,height,width,nop,scales,centers,joints = read_and_decode(filename_queue)\n",
    "    # separate joint locations and their visibility\n",
    "    joints_loc = tf.slice(joints,[0,0],[NUM_MPI_JOINTS*nop,2])\n",
    "    # convert matlab coordinate system to 0-based\n",
    "    joints_loc -= 1.0\n",
    "    joints_vis = tf.slice(joints,[0,2],[NUM_MPI_JOINTS*nop,1])\n",
    "    joints_vis = tf.squeeze(joints_vis)\n",
    "    \n",
    "    # apply image preprocessing\n",
    "    resized_image,resized_joints,resized_center = _random_resize(image,joints_loc,centers[0,:],scales[0])\n",
    "    crop_image,crop_joints = _crop_pad(resized_image, resized_center, resized_joints,IMAGE_SIZE_WITH_PADDING)\n",
    "    # generate joint heatmaps\n",
    "    reshaped_joints_loc = tf.reshape(crop_joints,[nop,NUM_MPI_JOINTS,2])\n",
    "    reshaped_joints_vis = tf.reshape(joints_vis,[nop,NUM_MPI_JOINTS])\n",
    "    heatmap_all = generate_heatmaps(IMAGE_SIZE_WITH_PADDING,\n",
    "                                    IMAGE_SIZE_WITH_PADDING,\n",
    "                                    reshaped_joints_loc,\n",
    "                                    reshaped_joints_vis,\n",
    "                                    nop)\n",
    "    image_label = tf.concat(2,[crop_image,heatmap_all])\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image_label = tf.random_crop(image_label, [IMAGE_SIZE, IMAGE_SIZE, 3+NUM_HEATMAPS*2])\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image_label = tf.image.random_flip_left_right(distorted_image_label)\n",
    "    distorted_image = tf.slice(distorted_image_label,[0,0,0],[IMAGE_SIZE,IMAGE_SIZE,3])\n",
    "    distorted_image = distorted_image * (1. / 255) - 0.5\n",
    "    distorted_label = tf.slice(distorted_image_label,[0,0,3],[IMAGE_SIZE,IMAGE_SIZE,NUM_HEATMAPS*2])\n",
    "    \n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.05\n",
    "    min_queue_examples = int(total_inputs *\n",
    "                            min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d images before starting to train. '\n",
    "            'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(distorted_image, distorted_label,\n",
    "                                            min_queue_examples, batch_size,\n",
    "                                            shuffle=True)\n",
    "    \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "        image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "        label: 3-D Tensor of [height, width, 30] of type.float32.\n",
    "        min_queue_examples: int32, minimum number of samples to retain\n",
    "          in the queue that provides of batches of examples.\n",
    "        batch_size: Number of images per batch.\n",
    "        shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "        labels: Labels. 3D tensor of [batch_size, height, width] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 2\n",
    "    if shuffle:\n",
    "        images, labels = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, labels = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    return images, labels\n",
    "    \n",
    "\n",
    "def plot_pose(joints):\n",
    "    nop = joints.shape[0]\n",
    "    for i in xrange(nop):\n",
    "        plt.plot(joints[i,:,0],joints[i,:,1],'ro')\n",
    "#     plt.plot(joints[RIGHT_ANKLE:RIGHT_WRIST,0], joints[RIGHT_ANKLE:RIGHT_WRIST,1], '-')\n",
    "#     plt.plot(joints[RIGHT_WRIST:NECK,0], joints[RIGHT_WRIST:NECK,1], '-')\n",
    "#     plt.plot(joints[[NECK,HEAD_TOP],0], joints[[NECK,HEAD_TOP],1], '-')\n",
    "    \n",
    "def blend_heatmap_with_image(heatmaps,image,alpha=0.5):\n",
    "    image_float = image.astype(np.float32)\n",
    "    image_float_half = image_float*(1.0-alpha)\n",
    "    for i in xrange(NUM_COMMON_JOINTS):\n",
    "        mapi = alpha*heatmaps[:,:,i]*image_float\n",
    "        image_float_half += mapi\n",
    "#     image_float[:,:,1] = image_float[:,:,1] * foreground\n",
    "#     image_float[:,:,2] = image_float[:,:,2] * foreground\n",
    "    output = image_float_half.astype(np.uint8)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 50 images before starting to train. This will take a few minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-4, started daemon 123145553375232)>,\n",
       " <Thread(Thread-5, started daemon 123145557581824)>,\n",
       " <Thread(Thread-6, started daemon 123145561788416)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIRECTORY = '/Users/xuehan.xiong/Google Drive/datasets/human_pose'\n",
    "# TFRECORD_FILE = os.path.join(DIRECTORY, 'MPI_test.tfrecords')\n",
    "\n",
    "# file_path = os.path.join(DIRECTORY,TFRECORD_FILE)\n",
    "# images,heatmaps = distorted_inputs([file_path],32,1000)\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(init)\n",
    "# # Start the queue runners.\n",
    "# tf.train.start_queue_runners(sess=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images_val,heatmaps_val = sess.run([images,heatmaps])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "0.997737\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAFkCAYAAAAJ0nGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzN5s3yRJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fd88910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print heatmaps_val[1,:,:,13]\n",
    "# plt.imshow(heatmaps_val[1,:,:,13],cmap='jet')\n",
    "# print np.amax(heatmaps_val[1,:,:,13])\n",
    "# index = 21\n",
    "# gray_image = cv2.cvtColor(images_val[index,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "# print heatmaps_val.shape\n",
    "# print gray_image.shape\n",
    "# gray_blend = blend_heatmap_with_image(heatmaps_val[index,:,:,:],gray_image)\n",
    "# plt.imshow(gray_blend,cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
