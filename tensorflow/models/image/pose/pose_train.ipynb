{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pose_input\n",
    "import pose_model\n",
    "from tensorflow.contrib.framework.python.ops import variables\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from six.moves import xrange\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 900\n",
    "INITIAL_LEARNING_RATE = 1.0E-1\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1\n",
    "MOVING_AVERAGE_DECAY = 0.9\n",
    "MOMENTUM = 0.9\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('tfrecord_path', '',\n",
    "                           \"\"\"Path to TF record \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/pose_train/',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_float('initial_learning_rate', 0.1,\n",
    "                            \"\"\"Initial learning rate.\"\"\")\n",
    "tf.app.flags.DEFINE_float('learning_rate_decay_factor', 0.1,\n",
    "                            \"\"\"Learning rate decay factor.\"\"\")\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.00001,\n",
    "                            \"\"\"Weight decay factor.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('decay_epochs', 10,\n",
    "                            \"\"\"Number of epoches per learning rate decay.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_epochs', 100,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64,\n",
    "                            \"\"\"Batch size.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_interval_secs', 600,\n",
    "                            \"\"\"Time interval to save checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "steps_per_epoch = int(math.ceil(float(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN)/float(FLAGS.batch_size)))\n",
    "decay_steps = FLAGS.decay_epochs*steps_per_epoch\n",
    "max_steps = FLAGS.max_epochs*steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with tf.Graph().as_default():\n",
    "        images, labels = pose_input.distorted_inputs(\n",
    "            [FLAGS.tfrecord_path],\n",
    "            FLAGS.batch_size,\n",
    "            NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN)\n",
    "\n",
    "        # Build a Graph that computes the logits predictions from the\n",
    "        # inference model.\n",
    "        heatmap0,heatmap1 = pose_model.inference(images,FLAGS.weight_decay)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = pose_model.loss(heatmap0, heatmap1, labels)\n",
    "        \n",
    "        # create a global step variable\n",
    "        global_step = variables.get_or_create_global_step()\n",
    "        # Decay the learning rate exponentially based on the number of steps.\n",
    "        lr = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n",
    "                                    global_step,\n",
    "                                    decay_steps,\n",
    "                                    FLAGS.learning_rate_decay_factor,\n",
    "                                    staircase=True)\n",
    "        tf.scalar_summary('learning_rate',lr)\n",
    "        # updates the model parameters.\n",
    "        opt = tf.train.MomentumOptimizer(lr,MOMENTUM,use_nesterov=True)\n",
    "        train_op = slim.learning.create_train_op(loss, optimizer=opt)    \n",
    "        slim.learning.train(train_op,FLAGS.train_dir,\n",
    "                           log_every_n_steps=1,\n",
    "                           save_interval_secs=FLAGS.save_interval_secs,\n",
    "                           number_of_steps=max_steps)\n",
    "        \n",
    "def main(unused_args):\n",
    "    if tf.gfile.Exists(FLAGS.train_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    train()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
