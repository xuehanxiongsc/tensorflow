{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        # Defaults are not specified since both keys are required.\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([],tf.string),\n",
    "            'label': tf.FixedLenFeature([],tf.string),\n",
    "            'height': tf.FixedLenFeature([],tf.int64),\n",
    "            'width': tf.FixedLenFeature([],tf.int64),\n",
    "            'depth': tf.FixedLenFeature([],tf.int64),\n",
    "        })\n",
    "    height = tf.cast(features['height'],tf.int32)\n",
    "    width = tf.cast(features['width'],tf.int32)\n",
    "    depth = tf.cast(features['depth'],tf.int32)\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, tf.pack([height, width, depth]))\n",
    "\n",
    "    label = tf.decode_raw(features['label'], tf.uint8)\n",
    "    label = tf.reshape(label, tf.pack([height, width, 1]))\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(filenames, batch_size, total_inputs):\n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "        filename: Path to the tensorflow record file.\n",
    "        batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "        labels: Labels. 3D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    # Both image and label are 3-D tensor\n",
    "    image,label = read_and_decode(filename_queue)\n",
    "    image_label = tf.concat(2,[image,label])\n",
    "    image_label = tf.cast(image_label, tf.float32)\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image_label = tf.random_crop(image_label, [height, width, 4])\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image_label = tf.image.random_flip_left_right(distorted_image_label)\n",
    "    distorted_image = tf.slice(distorted_image_label,[0,0,0],[IMAGE_SIZE,IMAGE_SIZE,3])\n",
    "    distorted_label = tf.slice(distorted_image_label,[0,0,3],[IMAGE_SIZE,IMAGE_SIZE,1])\n",
    "    distorted_label = tf.squeeze(distorted_label)\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    #distorted_image = tf.image.random_brightness(distorted_image,\n",
    "    #                                            max_delta=63)\n",
    "    #distorted_image = tf.image.random_contrast(distorted_image,\n",
    "    #                                            lower=0.2, upper=1.8)\n",
    "    distorted_image = distorted_image * (1. / 255) - 0.5\n",
    "    \n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(total_inputs *\n",
    "                            min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d images before starting to train. '\n",
    "            'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(distorted_image, distorted_label,\n",
    "                                            min_queue_examples, batch_size,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "        image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "        label: 2-D Tensor of [height, width]\n",
    "        min_queue_examples: int32, minimum number of samples to retain\n",
    "          in the queue that provides of batches of examples.\n",
    "        batch_size: Number of images per batch.\n",
    "        shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "        labels: Labels. 3D tensor of [batch_size, height, width] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 2\n",
    "    if shuffle:\n",
    "        images, labels = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, labels = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    return images, labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
